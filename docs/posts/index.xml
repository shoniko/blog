<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Oleksandr Paraska</title>
		<link>https://shoniko.com/posts/</link>
		<description>Recent content in Posts on Oleksandr Paraska</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Sun, 03 May 2020 00:00:00 +0000</lastBuildDate>
		<atom:link href="https://shoniko.com/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Self-organizations</title>
			<link>https://shoniko.com/posts/self-organizations/</link>
			<pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/self-organizations/</guid>
			<description>There are examples of systems with incredible organizational complexity in nature. Birds in flocks, fishes in schools, ants in swarms all seem to just chug away, each doing their little part, and yet together they produce these incredibly complex systems we marvel about.
They scale really well too. There are some ant super-colonies that have billions of members, like for example the super-colony in Southern Europe, which stretches for 6000km.¬†And some are extremely sophisticated.</description>
			<content type="html"><![CDATA[<p><img src="/images/murmuration.gif" alt="Picture of bird murmuration"></p>
<p>There are examples of systems with incredible organizational complexity in nature. Birds in flocks, fishes in schools, ants in swarms all seem to just chug away, each doing their little part, and yet together they produce these incredibly complex systems we marvel about.</p>
<p>They scale really well too. There are some ant super-colonies that have billions of members, like for example the <a href="http://news.bbc.co.uk/earth/hi/earth_news/newsid_8127000/8127519.stm">super-colony in Southern Europe, which stretches for 6000km</a>.¬†</p>
<p>And some are extremely sophisticated. Like leaf-cutter ants, who are¬†<a href="https://www.youtube.com/watch?v=RH3KYBMpxOU">practicing agriculture</a> and antibiotics for more than 50 million years now, long before humans figured it out. The silly little things purposefully grow fungus! Not an easy task, as you may know if you ever tried to get your own <a href="https://www.refinery29.com/en-ca/2020/03/9606502/sourdough-bread-with-starter-baking-trend">sourdough starter</a>.</p>
<p>There are some beautiful leadership lessons from insect societies. Let's call it swarm intelligence.</p>
<p>For example, when a swarm of bees sets out to move somewhere only roughly <a href="https://jeb.biologists.org/content/211/20/3287">5% of bees know where they are actually going</a>. The 5% who do know are the highly energetic &ldquo;streaker bees&rdquo; who constantly fly through the swarm with one goal - to just fly faster in the desired direction than anyone else in other directions.</p>
<p>Swarm intelligence is curious because it is more than just a wisdom of the smartest individuals. It produces behaviors no single individual is capable of. It is hard to get started, but is very resilient once it is has started.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Schools of Striped Eel Catfish take turns watching for predators while feeding on the ocean floor.<br><br>Credit: Abyss Dive Center Bali <a href="https://t.co/Pv5sZUYp9T">pic.twitter.com/Pv5sZUYp9T</a></p>&mdash; Wonder of Science (@wonderofscience) <a href="https://twitter.com/wonderofscience/status/1256204397672980480?ref_src=twsrc%5Etfw">May 1, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h2 id="organizations">Organizations</h2>
<p>One peculiar feature of self-organizations is that they have no &ldquo;leaders&rdquo;.</p>
<p>There are lots of cases of human self-organization. The whole concept of &ldquo;free markets&rdquo; is probably the biggest global experiment in that regard. But also perhaps an open source movement and bitcoin are all good examples cases of leader-less self-organizations.</p>
<p>As in animals, human self-organization produces incredibly powerful results. A human swarm intelligence can <a href="https://unanimous.ai/ai-wins-oscars/">predict the winners of Oscars, Kentucky Derby and Trump's 100 days approval rating</a>. It can also give us Linux, defeat Communism, establish a new digital world currency and much more.</p>
<p>But, as an example of &ldquo;free markets&rdquo; shows - such systems need to be tended to very carefully. They are working well only when they are in an equilibrium, and whoever is looking after them has to be very attuned to all the <a href="https://en.wikipedia.org/wiki/Self-organized_criticality_control">criticalities</a>. Swarms need managers.</p>
<p>Technology enables an ever increasing connectedness of human organizations. It lends us an opportunity to rely on swarm intelligence way more than before. But it also means that we need to be more mindful than before about the benefits and limits of such structures.</p>
<p>Management and leadership in a connected world is a bit like a political choice. How much should be left for self-organization? How much do you believe in the Free Market?</p>
<p>Obviously no right or wrong answers there. But there is one thing that is clear.</p>
<p>Everyone would benefit from being a bit more like a streaker bee. They are kind of cool.</p>
<p>Be a bee! üêù</p>
]]></content>
		</item>
		
		<item>
			<title>Intelligent content filtering</title>
			<link>https://shoniko.com/posts/icf/</link>
			<pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/icf/</guid>
			<description>How do you know what a cat is?
It is certainly something furry, four-legged with a head and tail. But so is a dog. And a mouse. It certainly is something that meows - but some cats do not meow, yet we still agree they are cats. We can even (hopefully) agree that in the picture above there are three cats, even though we see nine legs, do not hear any meows, and see completely different color patterns on each.</description>
			<content type="html"><![CDATA[<p><img src="/images/cats.jpg" alt="Cat image"></p>
<p>How do you know what a cat is?</p>
<p>It is certainly something furry, four-legged with a head and tail. But so is a dog. And a mouse. It certainly is something that meows - but some cats do not meow, yet we still agree they are cats. We can even (hopefully) agree that in the picture above there are three cats, even though we see nine legs, do not hear any meows, and see completely different color patterns on each.</p>
<p>The point is this: it is surprisingly difficult to define most of every day things we take for granted. Back in 2017, a couple of researchers wrote a paper where they tried to define what a physical container is. That paper is 60 pages long. One can probably also write a definition of a cat in a similar fashion, but it would be:</p>
<ul>
<li>Hilarious</li>
<li>Very labor intensive</li>
<li>Not necessarily transferrable to definitions of other entities - like &ldquo;chair&rdquo;.</li>
</ul>
<h3 id="so-how-does-this-relate-to-content-filtering-and-what-i-want-to-talk-about-today">So how does this relate to content filtering and what I want to talk about today?</h3>
<p>Defining a cat using a set of rules would be considered a &ldquo;symbolic&rdquo; approach to AI. Symbolic AI is a method most prominently used in the 90s, and it does have a lot of applications where it works fine.</p>
<p>However, for reasons described above, it does not really scale to a lot of real world concepts. Thus connectionism (in a form of Deep Learning) came along. In the connectionist world, there is no explicitly defined set of rules, rather there's just a dataset of training examples and an optimization objective which an algorithm should accomplish on its own.</p>
<p>A connectionist's cat is learned, not hard coded.</p>
<figure>
    <img src="/images/SymbolicVsConnectionistApple.png"
         alt="Symbolic vs connectionist"/> <figcaption>
            <h4>The concept of &#34;apple&#34; in symbolic and non-symbolic interpretations</h4><p>Source: <a href="https://web.media.mit.edu/~minsky/papers/SymbolicVs.Connectionist.html">https://web.media.mit.edu/~minsky/papers/SymbolicVs.Connectionist.html</a></p>
        </figcaption>
</figure>

<hr>
<h2 id="implications-for-the-web">Implications for the Web</h2>
<p>Most of the content filtering on the Web today is done using a set of rules (a.k.a filter lists). Even though those rules are rather simplistic for AI standards, it is reasonable to say that this is a symbolic AI. Knowledge is placed there, not learned.</p>
<p>Symbolic AI systems are also sometimes called &ldquo;expert systems&rdquo;, and I find it interesting to think about an ad blocker as an expert system.</p>
<p>As the Web evolves, ad blocking filters (rules) become more and more sophisticated and complex. They already went from simplistic rules like <em>&ldquo;hide elements that have feature X&rdquo;</em> to constructs like <em>&ldquo;hide elements which have property X, are nested within element Y with feature T and have a sibling Z with feature R&rdquo;</em>.</p>
<p>While this does still work in most cases, further evolution could be hard to maintain. On top of that, thanks to <a href="http://adblockplus.org/">Adblock Plus</a> and <a href="https://acceptableads.com/">Acceptable Ads</a>, recent developments of the Web push the advertising to be more subtle and merge with content even more.</p>
<p>Advertising can look like &ldquo;recommended&rdquo; items:</p>
<figure>
    <img src="/images/outbrain.png"
         alt="Recommended posts by Outbrain"/> <figcaption>
            <p>Recommended posts by Outbrain</p>
        </figcaption>
</figure>

<p>or like content itself:</p>
<figure>
    <img src="/images/native_ad.png"
         alt="Native advertising by Mercedes-Benz in Washington Post: https://www.washingtonpost.com/sf/brand-connect/mercedes/the-rise-of-the-superhuman/"/> <figcaption>
            <p>Native advertising by Mercedes-Benz in Washington Post: <a href="https://www.washingtonpost.com/sf/brand-connect/mercedes/the-rise-of-the-superhuman/">https://www.washingtonpost.com/sf/brand-connect/mercedes/the-rise-of-the-superhuman/</a></p>
        </figcaption>
</figure>

<p>It can also be in the form of Server Side Ad Insertion in media streams, sponsored messages in podcasts and YouTube, a paragraph in an otherwise interesting article, a logo on an image and more.</p>
<p>Some of these are already not addressable by content blockers - there is no language to write rules for those cases.</p>
<hr>
<h2 id="developing-software-20">Developing software 2.0</h2>
<p>So while an ad blocker as an expert system works, it explicitly tries to limit the scope of what it is. This is because, to list a few:</p>
<ul>
<li>The ad blocker only tries to block advertising, and nothing else</li>
<li>it blocks the same things for everyone - different users, subscribed to same filter lists (expert system) would see the same things blocked</li>
<li>it does not actually have a concept of an &ldquo;ad&rdquo; internally  - it only works on proxy concepts. If a website or ad delivery method changes, it stops working until someone fixes it</li>
<li>it constantly needs to increase the rule complexity. A constant game of cat and mouse with publishers who keep circumventing ad blockers causes this</li>
</ul>
<p>All of these limitations make perfect sense, and even with them it is extremely challenging to implement an ad blocker properly.</p>
<p>But let's just wonder for a second what would happen if we removed these restrictions? Yes, this could probably enable identifying advertising using much more subtle cues, but one thing for sure is that it will certainly increase the complexity of the whole ad blocking system. And that is assuming if it would be feasible at all.</p>
<p><strong>Unless we go away with a concept of ad blocker as a symbolic (expert) system and consider an ad blocker as a connectionist system.</strong></p>
<p>If we consider dropping explicit rules and rely on compiling datasets into models we would effectively arrive at a Software 2.0 implementation of a content filtering paradigm. Instead of a &ldquo;simple&rdquo; limited Software 1.0 system, we could have a much broader, and flexible, implementation in <a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Software 2.0</a>.</p>
<figure>
    <img src="/images/software20.png"
         alt="Illustration of Software 2.0 by Andrej Karpathy"/> <figcaption>
            <p>Illustration of Software 2.0 by Andrej Karpathy</p>
        </figcaption>
</figure>

<p>Software 2.0 systems can implement much more complex systems, if only for a fact that in a way it is not humans who write them. A Software 2.0 system can &ldquo;understand&rdquo; what a cat is. Or what the article is about. Or if a specific element on a page was likely paid for (ie advertising).</p>
<p>Paul Graham, captured a similar sentiment in this old tweet:</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We need a new AdBlock that (a) is less visible to sites and (b) doesn&#39;t rely on fixed strings.</p>&mdash; Paul Graham (@paulg) <a href="https://twitter.com/paulg/status/817300296204427264?ref_src=twsrc%5Etfw">January 6, 2017</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<hr>
<h2 id="how-to-get-there">How to get there?</h2>
<p><em><strong>Perhaps counter intuitively, real obstacles on a path to a more Software 2.0 content filtering is not a lack of research in machine learning and AI, or some exuberant costs for trainings needed. It is existing Software 1.0.</strong></em></p>
<p>All of the Web is built around ideas of expert systems. Browsers expect you to provide a list of CSS <strong>rules</strong> to modify how they display things. With <a href="https://developer.chrome.com/extensions/declarativeNetRequest">declarativeNetRequest</a> you are also expected to provide a list of <strong>rules</strong> to decide which URLs to block.</p>
<p>As the Web matures, browsers take on more and more power over user's online behavior. Since they were originally designed as &ldquo;User Agents&rdquo;, they try to provide some degree of control to their users, by implementing support for all these rules.</p>
<p>However <strong>would a real User Agent created in 2020 rely on rules to augment the user experience?</strong></p>
<p>More importantly, what are the chances such a User Agent would be successful in serving the User's interests when there are hundreds of models, trained on lots of user data, by big corporations trying to influence the User?</p>
<p>The movement to get the benefits of the AI transformation on the Web has already started, with <a href="https://www.tensorflow.org/js">tenslorflow.js</a>, <a href="https://github.com/Microsoft/onnxjs">onnx.js</a>, <a href="https://mil-tokyo.github.io/webdnn/docs/">webdnn</a> and other frameworks enabling machine learning models in browsers. <a href="https://mil-tokyo.github.io/webdnn/docs/">W3C Machine Learning community</a> group is also moving into the same direction, by trying to standardize on a fast and efficient way to run machine learning inference on the Web.</p>
<p>However merely enabling machine learning predictions is not enough, and a deeper transformation is likely needed. For example, maybe on top of supporting a list of CSS rules browsers could also support a list of machine learning models for augmenting the DOM? This is a change to the fabric of the Web, and WebKit/Safari has already started experimenting with this broader change with <a href="https://webkit.org/blog/7675/intelligent-tracking-prevention/"><strong>Intelligent Tracking Prevention</strong></a>.</p>
<p>But why stop at cookies and not apply the same kind of thinking to other areas of the Web? Perhaps with enough articulation from an ad blocking industry something like Intelligent Content Blocking can be standardized on? Hopefully a user will just need to decide on a provider.</p>
<hr>
<h2 id="eating-the-elephant">Eating the elephant</h2>
<p>It certainly is not obvious such a thing would be possible yet, but the only way forward I see is to try &ldquo;<a href="https://www.google.com/search?q=how+do+you+eat+an+elephant">eating an elephant one bite at a time</a>&quot;.</p>
<p>At <a href="https://eyeo.com/">eyeo</a> we have already started using machine learning as a complimentary resource for our ad blocking expert system. However, following this path will likely be ineffective without a community-wide effort to change the inner workings of the Web.¬†And that‚Äôs why it is better to start having discussions now.</p>
<p>Where are we going? What is our future? Is it useful to go beyond ads? Are we enabling content bubbles by allowing people to block specific content? How can we ensure adversarial robustness of such systems?</p>
<p>We may not need all the answers, but we need to have a joint understanding of the important questions.</p>
<p>I would like to leave you with perhaps the most important question of them all - do we want to enable users to block all the cats on the Web? Do we want CatBlock?</p>
<p>Let's discuss!</p>
]]></content>
		</item>
		
		<item>
			<title>Blocking the face of Donald Trump on the Web using AI</title>
			<link>https://shoniko.com/posts/shoniko/blocking-the-face-of-donald-trump-on-the-web-using-ai-a39f6ad7f69e/</link>
			<pubDate>Tue, 10 Jul 2018 19:39:29 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/shoniko/blocking-the-face-of-donald-trump-on-the-web-using-ai-a39f6ad7f69e/</guid>
			<description>Recently my employer Adblock Plus was having an annual Summer Team Week. Being a mostly distributed company it is a great opportunity to socialize and meet people you work with, but never get to see in real life.
As it often happens in these cases after some amount of social activities I overheard someone jokingly suggesting that us being a company which has this goal of ‚Äúputting you in charge of a fair and profitable Web‚Äù, we can just block the face of Donald Trump using some machine learning techniques.</description>
			<content type="html"><![CDATA[<p><img src="/images/1__lt3lFQRZgxww1OY0h7WXXw.png" alt=""></p>
<p>Recently my employer <a href="https://medium.com/u/ec2706a38f84">Adblock Plus</a> was having an annual Summer Team Week. Being a mostly distributed company it is a great opportunity to socialize and meet people you work with, but never get to see in real life.</p>
<p>As it often happens in these cases after some amount of social activities I overheard someone jokingly suggesting that us being a company which has this goal of ‚Äúputting you in charge of a fair and profitable Web‚Äù, we can just block the face of Donald Trump using some machine learning techniques. Because someone might want to do that¬†:) Challenge accepted, I thought.</p>
<p>As luck would have it I was just recently reading about the release of <a href="https://github.com/justadudewhohacks/face-api.js">face-api.js</a>‚Ää‚Äî‚ÄäJavaScript API for Face Recognition in the Browser with tensorflow.js. Armed with that, I quickly hacked together an extension that just goes through all the images in a web page and runs face-api.js inference on them. That all was easier than expected, however I discovered that some images cannot be retrieved for inference because of something called ‚Äú<a href="https://stackoverflow.com/questions/22710627/tainted-canvases-may-not-be-exported">Canvas Tainting</a>‚Äù. Essentially there is a security policy on image data, which guarantees that only scripts from the domain which loaded the image can access the image data.</p>
<p>After a quick brainstorm I have resorted to loading a separate copy of an image from the background script, which shouldn‚Äôt be a big deal, as in most cases the images are cached anyway. With that change the extension started working. However since face recognition using a neural network is pretty resource intensive on some web pages the face recognition took way too long. So I enforced an artificial limit on the size of an image that extension would run inference on‚Ää‚Äî‚Äädimensions larger than 150px. Thinking is that anything smaller than that doesn‚Äôt really matter much anyway.</p>
<p>Next, I had to compare the extracted face features to features of the face of Donald Trump. For that I have bundled an <a href="https://upload.wikimedia.org/wikipedia/commons/5/56/Donald_Trump_official_portrait.jpg">official portrait</a> within the extension and just extracted the features from it when the extension initializes. This means that in theory any face can be targeted, just replace the `<a href="https://github.com/shoniko/trumpblock/blob/master/icons/detailed/Donald_Trump_official_portrait.jpg">icons/detailed/Donald_Trump_official_portrait.jpg</a>` with your reference image. And since the `carrot` image is also easily replaceable the extension can be taken to a lot of different directions. For example I have <a href="https://news.sky.com/story/china-censors-winnie-the-pooh-social-media-posts-amid-xi-criticism-11270677">heard</a> president Xi of China especially enjoys being compared to Winnie the Pooh¬†;)</p>
<p>So there it is‚Ää‚Äî‚Ää<a href="https://chrome.google.com/webstore/detail/trump-face-block/jhdiboefiphoflmekjffaccgbhachicn">Trump Face Block</a>, available now on <a href="https://chrome.google.com/webstore/detail/trump-face-block/jhdiboefiphoflmekjffaccgbhachicn">Chrome Web Store</a> and on <a href="https://github.com/shoniko/trumpblock">GitHub</a>.</p>
]]></content>
		</item>
		
		<item>
			<title>Towards more intelligent ad blocking on the web</title>
			<link>https://shoniko.com/posts/shoniko/towards-more-intelligent-ad-blocking-on-the-web-9f67bf2a12b5/</link>
			<pubDate>Sun, 24 Jun 2018 21:30:22 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/shoniko/towards-more-intelligent-ad-blocking-on-the-web-9f67bf2a12b5/</guid>
			<description>Ad blockers of today rely heavily on a community of filter authors, who are continuously adding, changing and removing the filters which define what is blocked or what is considered an ad. It is quite a laborious task, often requiring constantly visiting the same websites again and again, just to make sure the stuff that is supposed to be blocked gets blocked, and stuff that should not‚Ää‚Äî‚Äädoesn‚Äôt.
To alleviate some of the pain points of this process it would be useful to automate some routine parts, while keeping human authors doing what they do best‚Ää‚Äî‚Ääjudging what constitutes an ad.</description>
			<content type="html"><![CDATA[<p>Ad blockers of today rely heavily on a community of filter authors, who are continuously adding, changing and removing the filters which define what is blocked or what is considered an ad. It is quite a laborious task, often requiring constantly visiting the same websites again and again, just to make sure the stuff that is supposed to be blocked gets blocked, and stuff that should not‚Ää‚Äî‚Äädoesn‚Äôt.</p>
<p>To alleviate some of the pain points of this process it would be useful to automate some routine parts, while keeping human authors doing what they do best‚Ää‚Äî‚Ääjudging what constitutes an ad.</p>
<p>A recent <a href="https://adblockplus.org/blog/ping-pong-with-facebook">arms race</a> between Adblock Plus and Facebook prompted a <a href="http://randomwalker.info/publications/ad-blocking-framework-techniques.pdf">research paper</a> at Princeton, which suggested the concept of a ‚Äúperceptual ad blocker.‚Äù And while Adblock Plus is still able to block Facebook ads today, the concept is interesting to explore. Here is a quote from the paper.</p>
<blockquote>
<p>We rely on the key insight that ads are legally required to be clearly recognizable by humans. To make the method robust, we deliberately ignore all signals invisible to humans, including URLs and markup. Instead we consider visual and behavioral information</p>
</blockquote>
<p>Another key insight comes from one of the most influential minds in Artificial Intelligence and Deep Learning, Andrew Ng.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Pretty much anything that a normal person can do in &lt;1 sec, we can now automate with AI.</p>&mdash; Andrew Ng (@AndrewYNg) <a href="https://twitter.com/AndrewYNg/status/788548053745569792?ref_src=twsrc%5Etfw">October 19, 2016</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Since, generally speaking, a normal person can distinguish an ad from a non-ad in less than one second, it makes sense to explore how we can harness AI to help the filter list community.</p>
<p>To mimic the way humans see the web we‚Äôll be looking at screenshots of websites, not actual code. The thinking is that whatever happens in the code, the end result is presented to a human user visually; so that‚Äôs where we should operate.</p>
<p>With that background, the problem becomes clearer. Given merely a screenshot of a website, identify where the ads on that screenshot are. If we are able to do that, then we‚Äôll be able to automatically crawl the web, detect ads automatically on sites where such an approach is possible, and, in parallel, flag websites if they should be checked by human contributors.</p>
<p>This is known as an ‚Äúobject detection‚Äù task in the machine learning world. There are multiple algorithms to solve this, including:</p>
<ul>
<li><a href="https://arxiv.org/abs/1311.2524"><strong>R-CNN</strong>: Region-based Convolutional Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1512.02325"><strong>SSD</strong>: Single Shot Detection</a></li>
<li><a href="https://arxiv.org/pdf/1612.08242.pdf"><strong>YOLO</strong>: You Only Look Once</a></li>
</ul>
<figure>
    <img src="/images/1__qHgdrIphDggxi3SfDWhlEw.png"
         alt="Table of mAP results from YOLO9000"/> <figcaption>
            <p>Source: YOLO9000 paper <a href="https://arxiv.org/pdf/1612.08242.pdf">https://arxiv.org/pdf/1612.08242.pdf</a></p>
        </figcaption>
</figure>

<p>Mean average precision (mAP) is generally agreed to be a good metric for performance of an object detection algorithm. There is a great explanation of what it is <a href="https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173">here</a>, but essentially it is a metric of how closely predicted bounding boxes come to expected bounding boxes. Based on this metric, and the speed of inference, the updated versions of You Only Look Once (YOLO) are widely considered the most efficient object detection algorithms. That is why we decided to use YOLO in this case.</p>
<p>However, screenshots of web pages are very specific data, and it would be beneficial to the research to compare results of different algorithms on this specific task. The results of this will be released in follow up posts. We will also use different feature extractors in YOLOv2 implementation to get a better intuition on what different kinds of networks would learn.</p>
<p>As YOLO is a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine learning</a> algorithm, to train our model we would need a list of screenshots, annotated with bounding boxes for ads. Luckily, we can generate as many screenshots of websites as needed, and thanks to all the work of Easylist authors we can automatically generate the annotations too. As a proof-of-concept, we‚Äôll be using the above mentioned ads on Facebook.</p>
<figure>
    <img src="/images/1__XYW8MkEElxPniLfZbGzzqA.png"
         alt="A diagram of Facebook"/> <figcaption>
            <p>Source: <a href="https://getpayever.com/facebook-ads-for-beginners-guide/">https://getpayever.com/facebook-ads-for-beginners-guide/</a></p>
        </figcaption>
</figure>

<p>Facebook ads are an example of native ads, and in this special case both the content and ads are controlled by the same entity. To get training data from Facebook we‚Äôll implement a simple script that will instruct the browser to continuously scroll a Facebook feed, make screenshots and write annotations. Using a WebDriver API we can use the <a href="http://webdriver.io/api/protocol/screenshot.html">screenshot</a> function to produce a training image, and <a href="http://webdriver.io/api/property/getLocation.html">getLocation</a> to retrieve the element‚Äôs bounding box. Immediately a few caveats pop up:</p>
<ul>
<li>we have to be mindful about the screen resolution <a href="https://en.wikipedia.org/wiki/Dots_per_inch">dpi</a>, as browsers report element locations in native web page pixels, and screenshots are in end-user pixels.</li>
<li>Facebook has to be continuously scrolled, meaning that the reported locations of elements must be adjusted by `_window.pageYOffset`._</li>
<li>Turns out Facebook is not endless!</li>
</ul>
<figure>
    <img src="/images/1__IZeXRYcGAmC1SYkrpCrqPg.png"
         alt="A visualization of the end of Facebook"/> <figcaption>
            <p>The end of¬†Facebook</p>
        </figcaption>
</figure>

<p>One important thing to consider is that Facebook news feed ads look very much like regular entries, with very few distinguishing characteristics of their own. To make sure our neural network does not treat regular news feed entries as ads we have to show it examples of both ads and non-ads. So our script has to capture boxes of three classes:</p>
<ul>
<li>a news feed item,</li>
<li>a news feed ad and</li>
<li>a side ad to the right of the news feed.</li>
</ul>
<p>After letting the script crawl Facebook for a few hours, we‚Äôll end-up with a list of images and their annotations. However, because all of the screenshots are of the same size and ads are roughly in same location in each screenshot, we risk having the neural network overfitting to the location, rather than other ad features. We try to overcome that by running a script in a browser with different dimensions.</p>
<p>Implementing YOLOv2 from scratch is a pretty involved task, but luckily there are already implementations for various frameworks. For example, TensorFlow has a <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">research section with object detection API</a> built in. Nvidia DIGITS has a <a href="https://github.com/NVIDIA/DIGITS/tree/master/examples/object-detection">UI layer for object detection</a> as well. Microsoft has just released an <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home">object detection extension for their Custom Vision API</a>. For this exercise, however, for research purposes we will rely on another open source <a href="https://github.com/experiencor/keras-yolo2">implementation of YOLOv2 for Keras</a>.</p>
<p>For our implementation, the annotations are simple XML files, which are located in a separate directory from training screenshots. For proof of concept, we have produced a data set of 7948 screenshots. In the data set there are 15902 examples of a news feed item, 1502 examples of a news feed ad and 3494 examples of a side ad. We can then divide the data set into 3 groups‚Ää‚Äî‚Äätraining, cross-validation and test set; approximately 80%, 10%, 10%, respectively. With this training set up we are achieving a 0.93 mAP score with YOLOv2 network with 608x608 input data. 0.9883 for news feed items, 0.9234 for news feed ads and 0.8919 for side ads. The scores are quite high, as the generated data is very homogenous. So in a way we are over-fitting to synthetic data, but it is fine for the defined task.</p>
<p>Such a set up produces fairly good recall, and we can identify where the objects are:</p>
<p><img src="img%5C1__zz76WjN4rNNy0RVB4tZHAA.png" alt="">
<img src="img%5C1__hWZ2W3DC__ummbvCt1a2L5A.png" alt=""></p>
<p>It also looks like we are able to figure out some features of ads vs non-ads, but more work in this area can certainly be done. It would also be interesting to compare the model performance with human reference, as Facebook ads are masked as native content.</p>
<p><img src="img%5C1____C8H3t__KbOjA8__K3Gesjew.png" alt=""></p>
<p>For some intuition of what the model learned, here is a recorded video of the trained model performing inference (not real time):</p>
<p>Running inference on every frame</p>
<p>As expected, it looks like a full news feed item, with ‚ÄúSuggested post‚Äù on top is classified as an ad fairly reliably. It doesn‚Äôt look like the model has picked up on ‚ÄúSponsored‚Äù text yet though. This is something we can focus for future research.</p>
<p>We have set out to train a model to detect Facebook ads. So far we have been training and evaluating on `synthetic` data, produced by a script scrolling the Facebook news feed. We got some fairly good results, but we also wanted to make sure our model can generalize well, so that what the model considers an ad would approximate very closely what people consider an ad. We thought it would be helpful to involve the community here. For that we have <a href="https://github.com/shoniko/keras-yolo2/blob/dacd7a089f09a9735e0aad4fa61d50fcce19098d/convert_keras_to_tf.py">exported</a> the trained Keras model to a saved TensorFlow model (.pb) and set up a TensorFlow Serving instance to serve it. We have also created a <a href="https://github.com/shoniko/adblock-ai-backend/tree/fa819a9050429345285415b665f04788c9461325/facebook-bot">Facebook bot</a> and wrapped it inside a Flask server, hosted using Gunicorn. The Bot accepts screenshots from users, prepares them for the TensorFlow graph and passes them to the <a href="https://github.com/shoniko/adblock-ai-backend/blob/fa819a9050429345285415b665f04788c9461325/inference/Dockerfile">TensorFlow Serving instance</a>. We orchestrate our setup using <a href="https://github.com/shoniko/adblock-ai-backend/blob/fa819a9050429345285415b665f04788c9461325/docker-compose.yml">docker-compose</a>. All code is available <a href="https://github.com/shoniko/facebook-ad-detector">here</a>. We anticipate the Bot will not be as good on user submitted screenshot data, as it is inherently different in nature. And also, there are apparently <a href="https://www.entrepreneur.com/article/294242">10 000 versions of Facebook</a> on the Web. However we plan to retrain our model with a dataset of user submitted screenshots and make it better over time.</p>
<p>This is only preliminary research on possible uses of Machine Learning methods for making the Web better. While there‚Äôs a lot more to try, the approach described here can already help the filter list community. We can now set up an automated crawling process to go on pages and render them to see exactly what the user would see. Based on those renders we can make decisions if a human filter list author should check the page.</p>
]]></content>
		</item>
		
		<item>
			<title>Optimize for happiness</title>
			<link>https://shoniko.com/posts/optimize-for-happiness/</link>
			<pubDate>Sun, 15 Apr 2007 00:00:00 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/optimize-for-happiness/</guid>
			<description>Optimize for happiness  Note: this is a copy of an original post from my Blogspot. It is a very old post, and does not necessary reflect my position now. I just keep it here for future references.
 Recently I came across the idea of happiness optimization. It basicly says something like - do what you like to do - that way the product will be better, and you wil be happier.</description>
			<content type="html"><![CDATA[<h2 id="optimize-for-happiness">Optimize for happiness</h2>
<blockquote>
<p>Note: this is a copy of an original post from my <a href="https://shoniko.blogspot.com/2007/04/optimize-for-happiness.html">Blogspot</a>. It is a very old post, and does not necessary reflect my position now. I just keep it here for future references.</p>
</blockquote>
<p>Recently I came across the idea of happiness optimization. It basicly says something like - do what you like to do - that way the product will be better, and you wil be happier.</p>
<p>I never concidered my self a great programmer. That is true. I never liked programming contests, as I'm not really sure what are those for. I beleive that a good programmer is a happy programmer. And that is it. Which is why I've decided to optimize for happiness.</p>
<p>Maybe I'm too much motivation driven, but I really think that satisfaction from the job is obligatory.</p>
<p>I really think that programmers should have life. If you ever read Douglass Coupland's &ldquo;Microsofters&rdquo; I think you'll know what I mean. By life I mean girlfriend, parties, trips, friends, etc. This is mandatory. Ofcourse there are nightly shifts etc, but programmer is a human beeing, and he/she should be able to have fun. Code shouldn't be the meaning of the life. Life should. I don't see the reason to write a good code by sacrificing even the smallest peace of your own life. Maybe opensource commnity will strongly disagree with me on that :).</p>
<p>I remember some interview with Linus Torwalds, where he was describing his first steps in programming. Oh common - who can think now programming on machine language can be fun? Obviously he can. I remember it was something like: &ldquo;And look, I change this bit - and it moves! wow! cool!&quot;. Didn't we all had a simiar feeling? Don't we all love the possibilities thos machines give us in controlling themselves? Isn't THAT fun? Isn't THAT art or whatever you call it? Isn't THAT why we all are so into it?</p>
<p>One of the reasons I've started programming was to get more into various audio stuff, as I was keen of producing music. And it was really something - to hear those lines of code producing sound. That was my wow. That is my inspiration. I hate working without inspiration and I actually don'r remember if I ever did. I really don't know what was &ldquo;wow&rdquo; for those programmer–≤ who love Database programming - that is like fata morgana to me. Man is that boring?</p>
<p>So this is my current position as to what should the work look like - work should be fun. Otherwise it's not yours and you will do a great favor to yourself and others by turning around and looking for something more suitable for you. I'm pretty sure this will change in future, when I will be a bit older and would like to have a static home and job. Right now that is not for me, so I've decided to quit SoftServe and register as an enterpreneur with a state.</p>
<p>Thanks to all of SoftServe employees for being patient to my weirdness that was bugging them sometimes;).</p>
]]></content>
		</item>
		
		<item>
			<title>ML meetup</title>
			<link>https://shoniko.com/posts/draft_ml-meetup-7c7fbb380489/</link>
			<pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
			
			<guid>https://shoniko.com/posts/draft_ml-meetup-7c7fbb380489/</guid>
			<description>eyeo is proud to host a Cologne AI and Machine Learning meetup. This meetup is focused on AI explainability and of course with our exploration of the use of machine learning for ad blocking we are very interested in the topic as well.
Explainabile AI (XAI) is an old problem of the field, but with recent advances mostly in Deep Learning it became much more prominent. After all people do want to know why a medical AI made this diagnosis as opposed to another one, or why did the autonomous vehicle take that specific action.</description>
			<content type="html"><![CDATA[<p>eyeo is proud to host a <a href="https://www.meetup.com/Cologne-AI-and-Machine-Learning-Meetup/events/258559150/">Cologne AI and Machine Learning meetup</a>. This meetup is focused on AI explainability and of course with our exploration of the use of machine learning for ad blocking we are very interested in the topic as well.</p>
<p>Explainabile AI (XAI) is an old problem of the field, but with recent advances mostly in Deep Learning it became much more prominent. After all people do want to know why a medical AI made this diagnosis as opposed to another one, or why did the autonomous vehicle take that specific action.</p>
<p>In the context of ad blocking, however, explainable AI question also quickly gains a whole lot of social connotations. If it‚Äôs an AI that‚Äôs making decisions about what to block, instead of a filter list community, we need to understand how that AI works so that we use it responsibly.</p>
<p>We want to know why our models make decisions they make, because we need to have them aligned with the user‚Äôs choice, which is key to everything we do. However, perhaps unsurprisingly, there are adversaries on the Web who are extremely motivated to bypass the user‚Äôs choice, aiming to trick the AI and force their ads on users. From that perspective we need to make sure our models are also robust against adversarial attacks.</p>
<p>On the meetup we will talk about how we see the questions of explainability and adversarial robustness as two sides of the same coin. We will talk about our experiment Sentinel and give some examples from the trenches about adversarial robustness.</p>
]]></content>
		</item>
		
	</channel>
</rss>
